\section{Motivación}
\begin{frame}{Motivación}
    
   \begin{itemize}[<+->]
       \item Los modelos de Deep Learning (DL) son \textbf{determinísticos}: estimaciones puntuales de parámetros y predicciones.
       \item Los modelos actuales de DL tienden a estar \textbf{sobreparametrizados}. Ej: GPT3 ($\sim$175 bill.) Y distintos parámetros pueden ajustarse bien en entrenamiento, pero arrojan resultados distintos en prueba. 
       \item No es posible saber si el modelo está prediciendo con certeza o solo adivinando.
       \item Relevante en áreas como medicina y vehículos autónomos.
       
       
   \end{itemize}
\end{frame}

\begin{frame}{Motivación}

    \uncover<1->{
        Ejemplo: softmax.
        \begin{center}
        \includegraphics[height=4.5cm]{presentaciones/img/softmax.png}
        \end{center}
    } 

    \uncover<2->{
        \begin{alertblock}{Concepto erróneo}
            El output del modelo \textbf{no equivale} a la incerteza del modelo.
        \end{alertblock}
    } 

   
\end{frame}

\begin{frame}{Objetivo}
    Obtener la \textbf{incerteza} de una red neuronal, mediante un modelo que:
    \begin{itemize}
        \item sea escalable para datasets grandes,
        \item sea escalable para modelos complejos (CNN, RNN, etc.),
        \item use modelos ya existentes y
        \item sea fácil de entender y usar para personas no expertas.
    \end{itemize}
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Modelamiento bayesiano}

\begin{frame}{Modelamiento bayesiano}
    Dadas las observaciones $\bX, \bY$ se desea encontrar los parámetros $\bomega$ tal que $\by \approx \fb^{\bomega}(\bx)$. Para esto se intenta \textbf{maximizar} la posterior:
    \begin{equation}
        p(\bomega|\bX,\bY) = \dfrac{p(\bY|\bX,\bomega)p(\bomega)}{p(\bY|\bX)},
    \end{equation}
    
    Utilizando esto se puede realizar una predicción utilizando un nuevo punto $\bx^*$ integrando
    \begin{equation}
        p(\by^* | \bx^*, \bX, \bY) = \int p(\by^* | \bx^*, \bomega) p(\bomega | \bX, \bY) \dif \bomega
    \end{equation}
    
    Por lo general, la expresión $p(\bomega|\bX,\bY)$ es intratable, con lo que se utilizará inferencia variacional para obtener una aproximación.
    
    % siendo $p(\bY|\bX)$ la \textbf{evidencia}, dada por:
    
    % \begin{equation}
    %     p(\bY|\bX) = \int p(\bY|\bX,\bomega) p(\bomega) d\bomega.
    % \end{equation}
    
    % Sin embargo, en general esta integral no puede ser calculada analíticamente. Por lo tanto, se requiere una \textbf{aproximación}.
\end{frame}

\subsection{Inferencia variacional}

\begin{frame}{Inferencia variacional}


    \uncover<1->{
    Se define una \textbf{distribución variacional aproximada} $q_\theta(\bomega)$ parametrizada por $\theta$, cuya estructura sea fácil de evaluar.
    \begin{equation}
        q^*_\theta(\bomega) = \argmin_\theta \ \KL\{q_\theta(\bomega)||p(\bomega|\bX,\bY)\}
    \end{equation}
   } 

    \uncover<2->{
     Esto es equivalente a maximizar la \textbf{cota inferior de la evidencia (ELBO)}:
    \vspace{-5pt}
    \begin{equation}
        \ELBO(q) = \esp_{q_\theta(\bomega)}\{\ \log p(\bY|\bX,\bomega)\} - \KL\{q_\theta(\bomega)|| p(\bomega)\} := \L_{\VI}(\theta)
    \end{equation}
   } 
    
    \uncover<3->{
      \begin{exampleblock}{Ventajas}
        \begin{itemize}
            \item Balance: complejidad vs. ajuste de los datos.
            \item Captura la incerteza del modelo.
        \end{itemize}
    \end{exampleblock}
   } 
    
    
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Bayesian Deep Learning}

\begin{frame}{Bayesian Neural Networks (BNN)}
    En una Red Neuronal Bayesiana se modelan los pesos por medio de una distribución. 
    % Es decir, dadas las matrices de pesos $\bW_i$ y vectores de bias $\bb_i$ para la capa $i$, se asume un prior sobre las matrices de pesos, $p(\bW_i) = \N(\bm{0}, \bm{I})$
    \begin{figure}[H]
        \centering
        \includegraphics[width=\linewidth]{presentaciones/img/comp_NN_con_BNN.jpg}
        \caption{Comparación de una red neuronal con una red neuronal bayesiana. Obtenido de \cite{blundell2015weight}.}
        \label{fig:comp_NN_con_BNN}
    \end{figure}
\end{frame}

\begin{frame}{Inferencia Variacional en una BNN}
    Recordar que se está buscando la distribución posterior de los pesos dados los datos: $p(\bomega | \bX, \bY)$. Cómo esta expresión es intratable, se aproxima a través de inferencia variacional. Consideramos a la distribución variacional aproximada $q_\theta(\bomega)$ como
    \begin{equation}
        q_\theta(\bomega) = \prod_{i=1}^{L} q_\theta (\bW_i) = \prod_{i, j, k} \N(w_{ijk}; m_{ijk}, \sigma^2_{ojk})
    \end{equation}
    
    Dónde el parámetro $\bomega = \{\bW_i, \bb_i\}_{i=1}^{L}$ corresponde a los pesos y bias de la red
\end{frame}

\begin{frame}{Bayesian Neural Networks (BNN)}
    
    Se considera un prior sobre los pesos de la NN, induciendo una distribución sobre un conjunto paramétrico de funciones.
    \begin{align}
        \begin{split}
            \L_{\VI}(\theta) &= \esp_{q_\theta(\bomega)}\{\log p(\bY|\bX,\bomega)\} - \KL\{q_\theta(\bomega)|| p(\bomega)\} \\
            &= \sum_{i=1}^N \esp_{q_\theta(\bomega)}\{\log p(\by_i|\fb^\bomega(\bx_i))\} - \KL\{q_\theta(\bomega)|| p(\bomega)\},
        \end{split}
    \end{align}

    siendo $\fb^\bomega(\bx_i)$ el output del modelo para $\bx_i$.
    
    
    \begin{exampleblock}{Ventajas}
        \begin{itemize}
            \item Robustos a overfitting.
            \item Estimación de la incerteza.
            \item Puede aprender con datasets pequeños.
        \end{itemize}
    \end{exampleblock}
\end{frame}


\begin{frame}{Bayesian Neural Networks (BNN)}


    \uncover<1->{
        \color{red} \textbf{¡PERO!} \color{black} Esta expresión de $\L_{\VI}(\theta)$:

        \begin{enumerate}
            \item requiere calcular sobre todo el dataset $\Rightarrow$ costoso, e
            \item intratable para modelos complejos (por ej. BNN con más de una capa).
        \end{enumerate}    
    } 
   
    \vspace{10pt}
    \uncover<2->{
        \color{green}
        \textbf{Solución:}
        \color{black}
        
        \begin{enumerate}[<+->]
            \item Usar minibatches.
            \begin{equation}
                \hat{\L}_{\VI}(\theta) = \dfrac{N}{M}\sum_{i\in \mathcal{S}} \esp_{q_\theta(\bomega)}\{\log p(\by_i|\fb^\bomega(\bx_i))\} - \KL\{q_\theta(\bomega)|| p(\bomega)\}
            \end{equation}
            
            \item Usar estimadores Monte Carlo.
    \end{enumerate}    
    } 
   
\end{frame}


\subsection{Monte Carlo}

\begin{frame}{Estimadores de Monte Carlo}

    \uncover<1->{
    \textbf{Objetivo:}
    \begin{itemize}
        \item Estimar la esperanza de la log-likelihood.
        \item Estimar la derivada de la esperanza de la log-likelihood (c/r a $\theta$).
    \end{itemize}
   } 
    
    \vspace{10pt}
    \uncover<2->{
    Existen 3 estimadores:
    
    \begin{enumerate}
        \item Score function estimator
        \item Pathwise derivative estimator
        \item Characteristic function estimator
    \end{enumerate}
    }
    
    
\end{frame}

\subsection{Stochastic Regularization Techniques}

\begin{frame}{SRTs}
     \begin{block}{Interpretación}
        Optimizar \textbf{cualquier} NN con dropout es \textbf{equivalente} a una forma de inferencia aproximada: los pesos óptimos de un dropout NN son los mismos que los parámetros variacionales óptimos de una BNN con la misma estructura.
    \end{block}
\end{frame}


\subsection{Análisis}

\begin{frame}{Análisis}
    un analisis
\end{frame}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Demo}

\begin{frame}{Demo}
    \begin{figure}[H]
        \centering
        \includegraphics[scale=0.2]{presentaciones/img/demopsx.jpg}
        \caption{Psx Demo}
        \label{psx}
    \end{figure}
\end{frame}

\section{Conclusión}

\begin{frame}{Conclusión}
    conclusiones
\end{frame}


\begin{frame}{Conclusión}
    \centering
    \Huge ¡Gracias!
\end{frame}

% \begin{frame}{Referencias}
%     \printbibliography
% \end{frame}

\begin{frame}{Tercera diapo}
    AQUÍ HAY MÁS INFO
     \begin{block}{Primer bloque}
        Aquí está el primer bloque
    \end{block}
    \begin{exampleblock}{Bloque de ejemplo}
        Aquí hay un bloque de ejemplo
    \end{exampleblock}
    \begin{alertblock}{Bloque de alerta}
        Aquí hay un bloque de alerta
    \end{alertblock}
\end{frame}
