{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bayesian_CNN",
      "provenance": [],
      "authorship_tag": "ABX9TyNpF7To0CP407LJDsg5bPrg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asolnn2a8/Bayesian-Deep-Learning/blob/main/Bayesian_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhUoQ-V2ssEA",
        "outputId": "d0f4154c-a12a-4d8e-ac01-566994082686",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install pyro-ppl"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyro-ppl in /usr/local/lib/python3.6/dist-packages (1.5.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (3.3.0)\n",
            "Requirement already satisfied: pyro-api>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (0.1.2)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (1.18.5)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (4.41.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from pyro-ppl) (1.7.0+cu101)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.6.0->pyro-ppl) (0.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.6.0->pyro-ppl) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.6.0->pyro-ppl) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXtIbL5An0jN"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import pyro\n",
        "from pyro.distributions import Normal, Categorical\n",
        "from pyro.infer import SVI, Trace_ELBO\n",
        "from pyro.optim import Adam\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import colors\n",
        "from IPython import display\n",
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data.dataset import Dataset"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pPdTNtZwPu6"
      },
      "source": [
        "## Load MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FI0GYNP8sDRF"
      },
      "source": [
        "# Load dataset\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('mnist-data/', train=True, download=True,\n",
        "                       transform=transforms.Compose([transforms.ToTensor(),])),\n",
        "        batch_size=128, shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('mnist-data/', train=False, transform=transforms.Compose([transforms.ToTensor(),])\n",
        "                       ),\n",
        "        batch_size=128, shuffle=True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K17E0cbSyx7V"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZT10A38s_N0"
      },
      "source": [
        "# Some required objects\n",
        "softplus = torch.nn.Softplus()\n",
        "log_softmax = nn.LogSoftmax(dim=1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8MPClAguzzB"
      },
      "source": [
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    #plt.imshow(npimg,  cmap='gray')\n",
        "    #fig.show(figsize=(1,1))\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(1, 1))\n",
        "    ax.imshow(npimg,  cmap='gray', interpolation='nearest')\n",
        "    plt.show()\n",
        "\n",
        "def give_uncertainities(x, num_samples=100):\n",
        "    sampled_models = [guide(net, None, None) for _ in range(num_samples)]\n",
        "    yhats = [F.log_softmax(model(x).data, 1).detach().numpy() for model in sampled_models]\n",
        "    return np.asarray(yhats)\n",
        "\n",
        "\n",
        "def predict(net, x, num_samples=10):\n",
        "    sampled_models = [guide(net, None, None) for _ in range(num_samples)]\n",
        "    yhats = [model(x).data for model in sampled_models]\n",
        "    mean = torch.mean(torch.stack(yhats), 0)\n",
        "    return np.argmax(mean.numpy(), axis=1)\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4HFEcDCO86q"
      },
      "source": [
        "# Bayesian CNN for MNIST classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSExbew52ANJ"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(320, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 320)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "net = CNN()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocHNNN-4PQeQ"
      },
      "source": [
        "def model(net, x_data, y_data):\n",
        "    \"\"\"\n",
        "    Bayesian model with the NN architecture from \"net\".\n",
        "    \"\"\"    \n",
        "    # Set Gaussian priors for weights of CNN\n",
        "    priors = {}\n",
        "\n",
        "    for name, param in net.state_dict().items():\n",
        "        priors[name] = Normal(loc=torch.zeros_like(param), scale=torch.ones_like(param))\n",
        "\n",
        "    # lift module parameters to random variables sampled from the priors\n",
        "    lifted_module = pyro.random_module(\"module\", net, priors)\n",
        "\n",
        "    # sample a regressor (which also samples w and b)\n",
        "    lifted_reg_model = lifted_module()\n",
        "    lhat = log_softmax(lifted_reg_model(x_data))\n",
        "    \n",
        "    # sample from categorigal distribution\n",
        "    pyro.sample(\"obs\", Categorical(logits=lhat), obs=y_data)\n",
        "\n",
        "\n",
        "def guide(net, x_data, y_data):\n",
        "    \"\"\"\n",
        "    Variational distribution that approximates the posterior p(w|X, Y) with a Gaussian distribution.\n",
        "    \"\"\"\n",
        "    priors = {}\n",
        "    for name, param in net.state_dict().items():\n",
        "        mu = pyro.param(name+'_mu', torch.randn_like(param))\n",
        "        sigma = softplus(pyro.param(name+'_sigma', torch.randn_like(param)))\n",
        "        priors[name] = Normal(loc=mu, scale=sigma)\n",
        "    \n",
        "    lifted_module = pyro.random_module(\"module\", net, priors)\n",
        "    \n",
        "    return lifted_module()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJR7UuC0Xnzt",
        "outputId": "8290cd62-9603-42b0-e980-f0456f05ab81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "optim = Adam({\"lr\": 0.01})\n",
        "svi = SVI(model, guide, optim, loss=Trace_ELBO())\n",
        "\n",
        "num_iterations = 5\n",
        "loss = 0\n",
        "\n",
        "for j in range(num_iterations):\n",
        "    loss = 0\n",
        "    for batch_id, data in enumerate(train_loader):\n",
        "        # calculate the loss and take a gradient step\n",
        "        loss += svi.step(net, data[0], data[1])\n",
        "    normalizer_train = len(train_loader.dataset)\n",
        "    total_epoch_loss_train = loss / normalizer_train\n",
        "    \n",
        "    print(\"Epoch {}/{} - Loss: {:.2f} \".format(j,\n",
        "                                               num_iterations,\n",
        "                                               total_epoch_loss_train))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pyro/primitives.py:406: FutureWarning: The `random_module` primitive is deprecated, and will be removed in a future release. Use `pyro.nn.Module` to create Bayesian modules from `torch.nn.Module` instances.\n",
            "  \"modules from `torch.nn.Module` instances.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/5 - Loss: 129.96 \n",
            "Epoch 1/5 - Loss: 43.86 \n",
            "Epoch 2/5 - Loss: 29.35 \n",
            "Epoch 3/5 - Loss: 22.85 \n",
            "Epoch 4/5 - Loss: 20.79 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMkUdhXKf8K8"
      },
      "source": [
        "### Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gXyDxFmXthh",
        "outputId": "eac7c286-5832-4470-b028-45bce8da8d75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "num_samples = 100\n",
        "\n",
        "print('Prediction when network is forced to predict')\n",
        "correct = 0\n",
        "total = 0\n",
        "for j, data in enumerate(test_loader):\n",
        "    images, labels = data\n",
        "    predicted = predict(net, images, num_samples)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels.numpy()).sum().item()\n",
        "print(\"accuracy: %d %%\" % (100 * correct / total))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction when network is forced to predict\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pyro/primitives.py:406: FutureWarning: The `random_module` primitive is deprecated, and will be removed in a future release. Use `pyro.nn.Module` to create Bayesian modules from `torch.nn.Module` instances.\n",
            "  \"modules from `torch.nn.Module` instances.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy: 10 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nL0avFZ34CDZ"
      },
      "source": [
        "# Bayesian MLP "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc2Y1bW6wtjM"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJyR150_wMNM"
      },
      "source": [
        "#### NN architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMwIDLA8qTDO"
      },
      "source": [
        "class NN(nn.Module):\n",
        "  \"\"\"\n",
        "  A simple MLP.\n",
        "  \"\"\"\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "      super(NN, self).__init__()\n",
        "      self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "      self.out = nn.Linear(hidden_size, output_size)\n",
        "      \n",
        "  def forward(self, x):\n",
        "      output = self.fc1(x)\n",
        "      output = F.relu(output)\n",
        "      output = self.out(output)\n",
        "      return output\n",
        "\n",
        "# Create model\n",
        "net = NN(28*28, 1024, 10)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bM1srUY4wy7D"
      },
      "source": [
        "#### Bayesian settings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PwDy2HA4WpT"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6k09U7LAs3fD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9caf465-baea-422d-83dc-b3e6787a0d3f"
      },
      "source": [
        "optim = Adam({\"lr\": 0.01})\n",
        "svi = SVI(model, guide, optim, loss=Trace_ELBO())\n",
        "\n",
        "num_iterations = 5\n",
        "loss = 0\n",
        "\n",
        "for j in range(num_iterations):\n",
        "    loss = 0\n",
        "    for batch_id, data in enumerate(train_loader):\n",
        "        # calculate the loss and take a gradient step\n",
        "        loss += svi.step(data[0].view(-1,28*28), data[1])\n",
        "    normalizer_train = len(train_loader.dataset)\n",
        "    total_epoch_loss_train = loss / normalizer_train\n",
        "    \n",
        "    print(\"Epoch {}/{} - Loss: {:.2f} \".format(j,\n",
        "                                               num_iterations,\n",
        "                                               total_epoch_loss_train))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pyro/primitives.py:406: FutureWarning: The `random_module` primitive is deprecated, and will be removed in a future release. Use `pyro.nn.Module` to create Bayesian modules from `torch.nn.Module` instances.\n",
            "  \"modules from `torch.nn.Module` instances.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0/5 - Loss: 2055.53 \n",
            "Epoch 1/5 - Loss: 354.31 \n",
            "Epoch 2/5 - Loss: 152.26 \n",
            "Epoch 3/5 - Loss: 109.38 \n",
            "Epoch 4/5 - Loss: 95.57 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdwJBEHr4fxY"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TfUd57ltYd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b58a32f-2ada-4c96-9b73-bcbce06e8b44"
      },
      "source": [
        "num_samples = 10\n",
        "\n",
        "print('Prediction when network is forced to predict')\n",
        "correct = 0\n",
        "total = 0\n",
        "for j, data in enumerate(test_loader):\n",
        "    images, labels = data\n",
        "    predicted = predict(images.view(-1,28*28))\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels.numpy()).sum().item()\n",
        "print(\"accuracy: %d %%\" % (100 * correct / total))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction when network is forced to predict\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pyro/primitives.py:406: FutureWarning: The `random_module` primitive is deprecated, and will be removed in a future release. Use `pyro.nn.Module` to create Bayesian modules from `torch.nn.Module` instances.\n",
            "  \"modules from `torch.nn.Module` instances.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "accuracy: 89 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}